{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/samuel0922/TEAM_SSAMJI/blob/main/disease_detection_FasterRCNN_00.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DVjr_fK21Nvh"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import glob\n",
        "import json\n",
        "import time\n",
        "import tqdm\n",
        "import random\n",
        "import shutil\n",
        "import pprint\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import cv2\n",
        "import albumentations\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt  \n",
        "import matplotlib.patches as patches\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, datasets, models\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "\n",
        "# 레이블 인덱스 딕셔너리\n",
        "\n",
        "label_idx_dict = {\n",
        "    'ROI': 0, 'a11': 1, 'a12': 2,  'a5': 3,\n",
        "    'a7' : 4, 'a9' : 5, 'b3' : 6,  'b4': 7,\n",
        "    'b5' : 8, 'b6' : 9, 'b7' : 10, 'b8': 11\n",
        "}\n",
        "\n",
        "# GPU가 있으면 GPU로 DEVICE를 설정\n",
        "\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "McfC80dgsqoj"
      },
      "outputs": [],
      "source": [
        "# 필요한 정보를 추출해 리턴해 주는 함수 정의\n",
        "\n",
        "def get_data_dict(data_dir, data_idx):\n",
        "    '''\n",
        "    학습에 필요힌 정보는?\n",
        "    1) 이미지 경로\n",
        "    2) bbox(대상 작물 좌표) 좌표값\n",
        "    3) pbox(병징들의 좌표) 좌표값\n",
        "    4) part label(병해의 레이블) \n",
        "        => N개의 병징에 대한 레이블인데... 레이블은 병해 1개이어야 함   \n",
        "    '''\n",
        "\n",
        "    # 데이터셋 경로, 데이터 인덱스, 데이터인덱스에 해당하는 json 파일을 오픈함\n",
        "    with open(os.path.join(data_dir, data_idx, f\"{data_idx}.json\"), \"r\") as f:\n",
        "\n",
        "        # 파일을 불러와서 data_json에 할당\n",
        "        data_json = json.load(f)\n",
        "\n",
        "    # json에서 이미지 경로를 찾아서 image_path에 할당    \n",
        "    image_path = os.path.join(data_dir, data_idx, data_json[\"description\"][\"image\"])\n",
        "\n",
        "    # json에서 bbox 좌표 찾아서 할당\n",
        "    bbox = data_json[\"annotations\"][\"bbox\"]\n",
        "\n",
        "    # json에서 pbox 좌표 찾아서 할당\n",
        "    bbox_part = data_json[\"annotations\"][\"part\"]\n",
        "\n",
        "    \n",
        "    '''\n",
        "    이 부분이 pbox(병징에 대한 bbox)에 대한 처리 부분임\n",
        "    '''\n",
        "    # part(병징)에 대한 좌표값이 없다면 병징 label은 None으로\n",
        "    if len(bbox_part) == 0:\n",
        "        bbox_part_label = None\n",
        "\n",
        "    # N개가 있다면 bbox_part_label(병징 레이블)에 할당     \n",
        "    else:\n",
        "        bbox_part_label = data_json[\"annotations\"][\"disease\"]\n",
        "\n",
        "    # 산출한 값들을 반환함.    \n",
        "    return {\n",
        "        \"image_path\": image_path,\n",
        "        \"bbox\": bbox,\n",
        "        \"bbox_part\": bbox_part,\n",
        "        \"bbox_part_label\": bbox_part_label\n",
        "    }\n",
        "\n",
        "# 바운딩 박스 좌표를 만들어 주는 함수\n",
        "def generate_box(bbox):\n",
        "    xmin = float(bbox['x'])\n",
        "    ymin = float(bbox['y'])\n",
        "    xmax = xmin + float(bbox['w'])\n",
        "    ymax = ymin + float(bbox['h'])\n",
        "    return [xmin, ymin, xmax, ymax]\n",
        "\n",
        "# label을 만들어 주는 함수\n",
        "def generate_label(label):\n",
        "    return label_idx_dict[label]\n",
        "\n",
        "# target값을 만들어 주는 함수 \n",
        "def generate_target(bboxes, bbox_part_label):\n",
        "    '''\n",
        "    bboxes(작물에 대한 bbox데이터)와 bbox_part_label(병징에 대한 레이블)을 받아\n",
        "    boxes(bbox 좌표값들)와 labels(레이블 값)을 반환해 줌\n",
        "    ??? 확인 => label은 무엇에 대한 레이블이어야 하는가?\n",
        "    '''\n",
        "    num_objs = len(bboxes)  # boxes의 갯수를 객체의 갯수로 할당\n",
        "    boxes = []   # 좌표값을 넣어줄 리스트를 선언\n",
        "\n",
        "    # 매개변수로 받은 bboxes(좌표값들) 리스트에서 하나씩 꺼내서\n",
        "    for bbox in bboxes:\n",
        "        boxes.append(generate_box(bbox))  # 좌표를 생성해 추가해줌\n",
        "\n",
        "    '''\n",
        "    label에 대한 처리 부분\n",
        "    ??? 확인 => \"ROI\"의 역할은??\n",
        "    '''\n",
        "\n",
        "    # 레이블인덱스사전 에서 \"ROI\"에 해당하는 값을 labels 리스트에 초기화       \n",
        "    labels = [generate_label(\"ROI\")]\n",
        "\n",
        "    # 매개변수로 받은 병징에 대한 label이 있는 경우.. 즉 병징이 있는 경우 \n",
        "    if bbox_part_label is not None:\n",
        "        '''\n",
        "        ??? 확인 => label 값에 (레이블인덱스사전에서 추출한 코드)*(객체수-1)을 더해주는게 무슨 의미?    \n",
        "        '''\n",
        "        labels += [generate_label(bbox_part_label)] * (num_objs - 1)\n",
        "    \n",
        "    # boxes, labels \n",
        "    boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
        "    labels = torch.as_tensor(labels, dtype=torch.int64) \n",
        "    \n",
        "    return {\n",
        "        \"boxes\": boxes,\n",
        "        \"labels\": labels\n",
        "    }\n",
        "\n",
        "\n",
        "class MaskDataset(object):\n",
        "    def __init__(self, data_dir, data_list, transforms):\n",
        "        '''\n",
        "        path: path to train folder or test folder\n",
        "        '''\n",
        "        self.data_dir = data_dir\n",
        "        self.data_list = data_list\n",
        "        self.transforms = transforms\n",
        "\n",
        "    def __len__(self): \n",
        "        return len(self.data_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        data_dict = get_data_dict(self.data_dir, self.data_list[idx])\n",
        "        \n",
        "        image_path = data_dict['image_path']\n",
        "        bboxes = data_dict[\"bbox\"] + data_dict[\"bbox_part\"]\n",
        "        bbox_part_label = data_dict[\"bbox_part_label\"]\n",
        "        \n",
        "        image = Image.open(image_path).convert(\"RGB\")\n",
        "        target = generate_target(bboxes, bbox_part_label)\n",
        "        \n",
        "        if self.transforms is not None:\n",
        "            image = self.transforms(image)\n",
        "        return image, target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qxs7sa2usqo8"
      },
      "outputs": [],
      "source": [
        "data_dir = \"./train\"\n",
        "data_list = sorted(os.listdir(data_dir))\n",
        "\n",
        "train_data_list = data_list[:int(len(data_list) * 0.8)]\n",
        "val_data_list = data_list[int(len(data_list) * 0.8):]\n",
        "\n",
        "train_ds = MaskDataset(\n",
        "    data_dir=data_dir,\n",
        "    data_list=train_data_list,\n",
        "    transforms = transforms.Compose([\n",
        "        transforms.ToTensor()\n",
        "    ]),\n",
        ")\n",
        "val_ds = MaskDataset(\n",
        "    data_dir=data_dir,\n",
        "    data_list=val_data_list,\n",
        "    transforms = transforms.Compose([\n",
        "        transforms.ToTensor()\n",
        "    ]),\n",
        ")\n",
        "train_dl = DataLoader(\n",
        "    train_ds, \n",
        "    batch_size=1,\n",
        "    shuffle=True, \n",
        "    num_workers=8,\n",
        "    collate_fn=lambda batch: tuple(zip(*batch))\n",
        ")\n",
        "val_dl = DataLoader(\n",
        "    val_ds, \n",
        "    batch_size=1,\n",
        "    shuffle=False,\n",
        "    num_workers=8,\n",
        "    collate_fn=lambda batch: tuple(zip(*batch))\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sam9tsxw3X6p"
      },
      "outputs": [],
      "source": [
        "n_classes = len(label_idx_dict) # 12\n",
        "\n",
        "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
        "model.roi_heads.box_predictor = FastRCNNPredictor(\n",
        "    model.roi_heads.box_predictor.cls_score.in_features,\n",
        "    n_classes\n",
        ")\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GX71SjWksqo-"
      },
      "outputs": [],
      "source": [
        "trainable_params = [p for p in model.parameters() if p.requires_grad]\n",
        "optimizer = torch.optim.Adam(trainable_params, lr=0.0001)\n",
        "    \n",
        "num_epochs = 50\n",
        "print('----------------------train start--------------------------')\n",
        "for epoch in range(num_epochs):\n",
        "    start = time.time()\n",
        "    model.train()\n",
        "    i = 0    \n",
        "    epoch_loss = 0\n",
        "    for images, targets in tqdm.tqdm(train_dl):\n",
        "        i += 1\n",
        "        images = list(image.to(device) for image in images)\n",
        "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
        "        loss_dict = model(images, targets) \n",
        "        losses = sum(loss for loss in loss_dict.values())        \n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        losses.backward()\n",
        "        optimizer.step() \n",
        "        epoch_loss += losses\n",
        "    print(f'epoch : {epoch+1}, Loss : {epoch_loss}, time : {time.time() - start}')    \n",
        "    \n",
        "torch.save(model.state_dict(),f'model_{num_epochs}.pt')\n",
        "model.load_state_dict(torch.load(f'model_{num_epochs}.pt'))\n",
        "print(f\"model saved: {f'model_{num_epochs}.pt'}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nznoMyHpsqpK"
      },
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(),f'model_{num_epochs}.pt')\n",
        "model.load_state_dict(torch.load(f'model_{num_epochs}.pt'))\n",
        "print(f\"model saved: {f'model_{num_epochs}.pt'}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zoqrGNFR3zEt"
      },
      "outputs": [],
      "source": [
        "def make_prediction(model, images, threshold):\n",
        "    model.eval()\n",
        "    preds = model(images)\n",
        "    for id in range(len(preds)) :\n",
        "        idx_list = []\n",
        "\n",
        "        for idx, score in enumerate(preds[id]['scores']) :\n",
        "            if score > threshold : \n",
        "                idx_list.append(idx)\n",
        "\n",
        "        preds[id]['boxes'] = preds[id]['boxes'][idx_list]\n",
        "        preds[id]['labels'] = preds[id]['labels'][idx_list]\n",
        "        preds[id]['scores'] = preds[id]['scores'][idx_list]\n",
        "\n",
        "    return preds\n",
        "\n",
        "\n",
        "\n",
        "label_idx_dict = {\n",
        "    'ROI': 0, 'a11': 1, 'a12': 2,  'a5': 3,\n",
        "    'a7' : 4, 'a9' : 5, 'b3' : 6,  'b4': 7,\n",
        "    'b5' : 8, 'b6' : 9, 'b7' : 10, 'b8': 11\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "def plot_image_from_output(img, annotation):\n",
        "    img = img.cpu().permute(1,2,0)\n",
        "    fig,ax = plt.subplots(1)\n",
        "    ax.imshow(img)\n",
        "    for idx in range(len(annotation[\"boxes\"])):\n",
        "        xmin, ymin, xmax, ymax = annotation[\"boxes\"][idx]\n",
        "        if annotation['labels'][idx] == 0 :\n",
        "            rect = patches.Rectangle((xmin,ymin),(xmax-xmin),(ymax-ymin),linewidth=2,edgecolor='r',facecolor='none')\n",
        "        else :\n",
        "            rect = patches.Rectangle((xmin,ymin),(xmax-xmin),(ymax-ymin),linewidth=2,edgecolor='g',facecolor='none')\n",
        "        ax.add_patch(rect)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "with torch.no_grad(): \n",
        "    # 테스트셋 배치사이즈= 2\n",
        "    for images, targets in val_dl:\n",
        "        images = list(image.to(device) for image in images)\n",
        "        preds = make_prediction(model, images, 0.5)\n",
        "        print(preds)\n",
        "        break\n",
        "    \n",
        "    \n",
        "_idx = 0\n",
        "print(\"Target : \", targets[_idx]['labels'])\n",
        "plot_image_from_output(images[_idx], targets[_idx])\n",
        "print(\"Prediction : \", preds[_idx]['labels'])\n",
        "plot_image_from_output(images[_idx], targets[_idx])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NPvK5oR8sqpT"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.9.12 ('ys_torch')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "vscode": {
      "interpreter": {
        "hash": "06b312d4da2a9a3686a6d52820f5105a519faf7cd6cc067e3b3e5e11d5973e41"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}